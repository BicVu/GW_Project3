{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://xcitech.github.io/tutorials/heroku_tutorial/\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df = pd.read_csv('Clean_Data/ML_2015_CLEAN.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GeoID', 'Year', 'D_Etab', 'D_Emp', 'D_Pay', 'G_Etab', 'G_Emp', 'G_Pay',\n",
       "       'Pop_2015', 'FD_num_2015', 'FD_pct_2015'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoID            int64\n",
      "Year             int64\n",
      "D_Etab           int64\n",
      "D_Emp            int64\n",
      "D_Pay            int64\n",
      "G_Etab           int64\n",
      "G_Emp            int64\n",
      "G_Pay            int64\n",
      "Pop_2015         int64\n",
      "FD_num_2015      int64\n",
      "FD_pct_2015    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeoID</th>\n",
       "      <th>Year</th>\n",
       "      <th>D_Etab</th>\n",
       "      <th>D_Emp</th>\n",
       "      <th>D_Pay</th>\n",
       "      <th>G_Etab</th>\n",
       "      <th>G_Emp</th>\n",
       "      <th>G_Pay</th>\n",
       "      <th>Pop_2015</th>\n",
       "      <th>FD_num_2015</th>\n",
       "      <th>FD_pct_2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>93</td>\n",
       "      <td>1703</td>\n",
       "      <td>5</td>\n",
       "      <td>283</td>\n",
       "      <td>5691</td>\n",
       "      <td>55035</td>\n",
       "      <td>17497</td>\n",
       "      <td>32.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>2015</td>\n",
       "      <td>50</td>\n",
       "      <td>429</td>\n",
       "      <td>7054</td>\n",
       "      <td>30</td>\n",
       "      <td>1774</td>\n",
       "      <td>36515</td>\n",
       "      <td>203690</td>\n",
       "      <td>30561</td>\n",
       "      <td>16.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>844</td>\n",
       "      <td>4</td>\n",
       "      <td>159</td>\n",
       "      <td>2733</td>\n",
       "      <td>26270</td>\n",
       "      <td>6070</td>\n",
       "      <td>22.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>596</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>2497</td>\n",
       "      <td>22561</td>\n",
       "      <td>969</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015</td>\n",
       "      <td>2015</td>\n",
       "      <td>34</td>\n",
       "      <td>263</td>\n",
       "      <td>4461</td>\n",
       "      <td>29</td>\n",
       "      <td>832</td>\n",
       "      <td>15066</td>\n",
       "      <td>115285</td>\n",
       "      <td>27786</td>\n",
       "      <td>23.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GeoID  Year  D_Etab  D_Emp  D_Pay  G_Etab  G_Emp  G_Pay  Pop_2015  \\\n",
       "0   1001  2015      11     93   1703       5    283   5691     55035   \n",
       "1   1003  2015      50    429   7054      30   1774  36515    203690   \n",
       "2   1005  2015       8     60    844       4    159   2733     26270   \n",
       "3   1007  2015       5     40    596       5    111   2497     22561   \n",
       "4   1015  2015      34    263   4461      29    832  15066    115285   \n",
       "\n",
       "   FD_num_2015  FD_pct_2015  \n",
       "0        17497        32.06  \n",
       "1        30561        16.77  \n",
       "2         6070        22.11  \n",
       "3          969         4.23  \n",
       "4        27786        23.43  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(read_df.dtypes)\n",
    "read_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only columns we want to use in ML\n",
    "# df = read_df[['D_Etab', 'G_Etab', 'Pop_2015', 'FD_num_2015', 'FD_pct_2015']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Dollar Store and Population\n",
    "read_df.plot(x='D_Etab', y='Pop_2015', style='o')  \n",
    "plt.title('Dollar Store & County Population')  \n",
    "plt.xlabel('Dollar Stores')  \n",
    "plt.ylabel('County Pop')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Very strong correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation between Dollar Stores & Pop with Low Access to food\n",
    "read_df.plot(x='D_Etab', y='FD_num_2015', style='o')  \n",
    "plt.title('Dollar Store & Low Food Access Population')  \n",
    "plt.xlabel('Dollar Stores')  \n",
    "plt.ylabel('Low Access Food Pop Count')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Strong correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Dollar Stores & Percent of Pop w Low Access\n",
    "read_df.plot(x='D_Etab', y='FD_pct_2015', style='o')  \n",
    "plt.title('Dollar Store & Low Food Access Percentage')  \n",
    "plt.xlabel('Dollar Stores')  \n",
    "plt.ylabel('Low Access Food Pop Percent')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Strange if not little correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Grocery Stores &  Pop with Low Access to food\n",
    "read_df.plot(x='G_Etab', y='FD_num_2015', style='o')  \n",
    "plt.title('Grocery Store & Low Food Access Population')  \n",
    "plt.xlabel('Grocery Stores')  \n",
    "plt.ylabel('Low Access Food Pop Count')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Why is this not a negative correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model & Set Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns for machine learning processing\n",
    "mldf = read_df[['D_Etab', 'G_Etab', 'Pop_2015', 'FD_num_2015']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['D_Etab', 'G_Etab', 'Pop_2015', 'FD_num_2015'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mldf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503, 3) (1503,)\n"
     ]
    }
   ],
   "source": [
    "X = mldf.drop(\"G_Etab\", axis=1) # drop target feature column\n",
    "y = mldf[\"G_Etab\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bic/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/bic/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "/Users/bic/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Scale Data with Standard Scaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "n_features = 3\n",
    "n_samples = len(mldf)\n",
    "X_train_std, y_train = make_regression(n_samples=n_samples, n_features=n_features, \n",
    "                       n_informative=n_features, random_state=42, \n",
    "                       noise=0.5, bias=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.63127582, -1.03854382, -0.37482206],\n",
       "       [ 0.29929258,  0.74209537, -0.60571492],\n",
       "       [ 1.16283858,  0.84310533,  1.84936214],\n",
       "       ...,\n",
       "       [-2.03923218, -1.18325851, -1.75873949],\n",
       "       [ 0.91922893, -1.43827798,  0.11327041],\n",
       "       [ 0.47200227,  0.49968511,  0.2394045 ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9999530549047398\n",
      "Testing Score: -0.8657702885696049\n"
     ]
    }
   ],
   "source": [
    "training_score = model.score(X_train_std, y_train)\n",
    "testing_score = model.score(X_test_std, y_test)\n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight coefficients:  [18.83300389 30.1674286  67.6849428 ]\n",
      "y-axis intercept:  99.98022291394365\n"
     ]
    }
   ],
   "source": [
    "print('Weight coefficients: ', model.coef_)\n",
    "print('y-axis intercept: ', model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1202,) (1503,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a6af2245baf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot data selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Testing Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1202,) (1503,) "
     ]
    }
   ],
   "source": [
    "# Plot data selection\n",
    "plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c=\"orange\", label=\"Testing Data\")\n",
    "\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y.min(), xmax=y.max())\n",
    "plt.title(\"Residual Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6</td>\n",
       "      <td>6.711814e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>9</td>\n",
       "      <td>1.479840e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>48</td>\n",
       "      <td>8.369727e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>11</td>\n",
       "      <td>1.783952e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>11</td>\n",
       "      <td>3.647887e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual     Predicted\n",
       "51         6  6.711814e+05\n",
       "1465       9  1.479840e+06\n",
       "184       48  8.369727e+06\n",
       "1000      11  1.783952e+06\n",
       "746       11  3.647887e+06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "print(len(check_df))\n",
    "check_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "n_features = 3\n",
    "n_samples = len(mldf)\n",
    "X_train, y_train = make_regression(n_samples=n_samples, n_features=n_features, \n",
    "                       n_informative=n_features, random_state=42, \n",
    "                       noise=0.5, bias=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Max Scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust Scaler\n",
    "# https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9\n",
    "\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# robust = RobustScaler(quantile_range = (0.1,0.9))\n",
    "# robust.fit_transform(X_train.f3.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler: Less sensitive to outliers\n",
    "# https://www.bogotobogo.com/python/scikit-learn/scikit_machine_learning_Data_Preprocessing-II-Datasets-Partitioning-Feature-scaling-Feature-Selection-Regularization.php\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled data comparison\n",
    "\n",
    "xx = np.arange(len(X_train_std))\n",
    "yy1 = X_train_scaled[:,1] # Overfitted\n",
    "yy2 = X_train_std[:,1]\n",
    "plt.scatter(xx, yy2, color='r')\n",
    "plt.scatter(xx, yy1, color='b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "print(len(check_df))\n",
    "check_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used example of Example 21.1.2 Stu_LSD\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_std, y_train)\n",
    "training_score = model.score(X_train_std, y_train)\n",
    "testing_score = model.score(X_test_std, y_test)\n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weight coefficients: ', model.coef_)\n",
    "print('y-axis intercept: ', model.intercept_)\n",
    "\n",
    "# 'D_Etab', 'D_Emp', 'D_Pay', 'G_Emp','G_Pay'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = np.array([[X.min()]])\n",
    "x_max = np.array([[X.max()]])\n",
    "print(f\"Min X Value: {x_min}\")\n",
    "print(f\"Max X Value: {x_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Residuals for the Training and Testing data\n",
    "\n",
    "plt.scatter(model.predict(X_train_std), model.predict(X_train_std) - y_train, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_std), model.predict(X_test_std) - y_test, c=\"orange\", label=\"Testing Data\")\n",
    "\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y.min(), xmax=y.max())\n",
    "plt.title(\"Residual Plot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test_std)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "print(len(check_df))\n",
    "check_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance of algorithm with error margins\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a Pickle ðŸ¥’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Regressor_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_lr_model =pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_lr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_load_predit=load_lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'reg_1.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_model= joblib.load('reg_1.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_param = {}\n",
    "model_param['coef'] = list(model.coef_)\n",
    "model_param['intercept'] = model.intercept_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_txt = json.dumps(model_param, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('regressor_param.txt', 'w') as file:\n",
    "    file.write(json_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('regressor_param.txt', 'r') as file:\n",
    "    json_text=json.load(file)\n",
    "json_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model (Cross Value model)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10], # how many times run\n",
    "              'gamma': [0.0001, 0.0005, 0.001]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_df = pd.DataFrame({'New':nn_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/make-predictions-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=11607, n_features=n_features, \n",
    "                       n_informative=n_features, random_state=42, \n",
    "                       noise=0.5, bias=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew, _ = make_regression(\n",
    "    n_samples=11607, n_features=n_features, noise=0.5, random_state=42)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_predictions = model.predict(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'New':new_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(-1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfit = xfit[:, np.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions, 'New':new_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More prediction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/time-series-forecast-study-python-monthly-sales-french-champagne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from statsmodels.tsa.arima_model import ARIMAResults\n",
    "import numpy\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = Series.from_csv('mldata_clean.csv')\n",
    "months_in_year = 12\n",
    "model_fit = ARIMAResults.load('model.pkl')\n",
    "bias = numpy.load('model_bias.npy')\n",
    "yhat = float(model_fit.forecast()[0])\n",
    "yhat = bias + inverse_difference(series.values, yhat, months_in_year)\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pipline\n",
    "pipe = make_pipeline(StandardScaler(), LinearRegression())\n",
    "pipe.fit(X_train_std, y_train)\n",
    "joblib.dump(pipe, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the saved model with joblib\n",
    "pipe = joblib.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data to predict\n",
    "pr = pd.read_csv('mldata_clean.csv')\n",
    "pred_cols = list(pr.columns.values)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the whole pipeline to data\n",
    "pred = pd.Series(pipe.predict(pr[pred_cols]))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
